{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fef143-f8d4-4078-9386-deeff2fd80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import imageio\n",
    "import bayes3d as b\n",
    "from tqdm import tqdm\n",
    "import pytorch3d.transforms as t3d\n",
    "import nvdiffrast.torch as dr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01981877",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17c219-e6ca-4a3b-a222-87078442decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter           = 10000\n",
    "repeats            = 1\n",
    "log_interval       = 10\n",
    "display_interval   = None\n",
    "display_res        = 512\n",
    "lr_base            = 0.01\n",
    "lr_falloff         = 1.0\n",
    "nr_base            = 1.0\n",
    "nr_falloff         = 1e-4\n",
    "grad_phase_start   = 0.5\n",
    "resolution         = 256\n",
    "out_dir            = None\n",
    "log_fn             = None\n",
    "mp4save_interval   = None\n",
    "mp4save_fn         = None\n",
    "use_opengl         = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ce3703-36df-4d82-bebc-751bb974c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection(x=0.1, n=1.0, f=50.0):\n",
    "    return np.array([[n/x,    0,            0,              0],\n",
    "                     [  0,  n/x,            0,              0],\n",
    "                     [  0,    0, -(f+n)/(f-n), -(2*f*n)/(f-n)],\n",
    "                     [  0,    0,           -1,              0]]).astype(np.float32)\n",
    "def translate(x, y, z):\n",
    "    return np.array([[1, 0, 0, x],\n",
    "                     [0, 1, 0, y],\n",
    "                     [0, 0, 1, z],\n",
    "                     [0, 0, 0, 1]]).astype(np.float32)\n",
    "glctx = dr.RasterizeGLContext() #if use_opengl else dr.RasterizeCudaContext()\n",
    "mvp = torch.tensor(np.matmul(projection(x=0.4), translate(0, 0, 0.0)).astype(np.float32), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fdf559-094d-46e5-ae8b-b75122891ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_to_matrix(poses: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert rotations given as quaternions to rotation matrices.\n",
    "\n",
    "    Args:\n",
    "        quaternions: quaternions with real part first,\n",
    "            as tensor of shape (..., 4).\n",
    "\n",
    "    Returns:\n",
    "        Rotation matrices as tensor of shape (..., 3, 3).\n",
    "    \"\"\"\n",
    "    positions = poses[...,:3]\n",
    "    quaternions = poses[...,3:]\n",
    "    r, i, j, k = torch.unbind(quaternions, -1)\n",
    "    x, y, z = torch.unbind(positions, -1)\n",
    "    # pyre-fixme[58]: `/` is not supported for operand types `float` and `Tensor`.\n",
    "    two_s = 2.0 / (quaternions * quaternions).sum(-1)\n",
    "\n",
    "    o = torch.stack(\n",
    "        (\n",
    "            1 - two_s * (j * j + k * k),\n",
    "            two_s * (i * j - k * r),\n",
    "            two_s * (i * k + j * r),\n",
    "            x,\n",
    "            two_s * (i * j + k * r),\n",
    "            1 - two_s * (i * i + k * k),\n",
    "            two_s * (j * k - i * r),\n",
    "            y,\n",
    "            two_s * (i * k - j * r),\n",
    "            two_s * (j * k + i * r),\n",
    "            1 - two_s * (i * i + j * j),\n",
    "            z,\n",
    "            0.0 * x,\n",
    "            0.0 * x,\n",
    "            0.0 * x,\n",
    "            0.0 * x + 1.0,\n",
    "        ),\n",
    "        -1,\n",
    "    )\n",
    "    rotation_matrices = o.reshape(quaternions.shape[:-1] + (4, 4))\n",
    "    return rotation_matrices\n",
    "\n",
    "# Transform vertex positions to clip space\n",
    "def transform_pos(mtx, pos):\n",
    "    t_mtx = torch.from_numpy(mtx).cuda() if isinstance(mtx, np.ndarray) else mtx\n",
    "    # (x,y,z) -> (x,y,z,1)\n",
    "    posw = torch.cat([pos, torch.ones([pos.shape[0], 1]).cuda()], axis=1)\n",
    "    return torch.matmul(posw, t_mtx.t())[None, ...]\n",
    "\n",
    "def render(glctx, mtx, pos, pos_idx, resolution: int):\n",
    "    # Setup TF graph for reference.\n",
    "    depth_ = pos[..., 2:3]\n",
    "    depth = torch.tensor([[[(z_val/1)] for z_val in depth_.squeeze()]], dtype=torch.float32).cuda()\n",
    "    pos_clip    = transform_pos(mtx, pos)\n",
    "    rast_out, _ = dr.rasterize(glctx, pos_clip, pos_idx, resolution=[resolution, resolution])\n",
    "    color   , _ = dr.interpolate(depth, rast_out, pos_idx)\n",
    "    # color       = dr.antialias(color, rast_out, pos_clip, pos_idx)\n",
    "    return color\n",
    "    # return rast_out[:,:,:,2:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c2c03-8f55-4625-982d-32479eebfa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/home/nishadgothoskar/bayes3d/nvdiffrast/samples/data\"\n",
    "with np.load(f'{datadir}/cube_p.npz') as f:\n",
    "    pos_idx, pos, col_idx, col = f.values()\n",
    "print(\"Mesh has %d triangles and %d vertices.\" % (pos_idx.shape[0], pos.shape[0]))\n",
    "\n",
    "# Some input geometry contains vertex positions in (N, 4) (with v[:,3]==1).  Drop\n",
    "# the last column in that case.\n",
    "if pos.shape[1] == 4: pos = pos[:, 0:3]\n",
    "\n",
    "# Create position/triangle index tensors\n",
    "pos_idx = torch.from_numpy(pos_idx.astype(np.int32)).cuda()\n",
    "vtx_pos = torch.from_numpy(pos.astype(np.float32)).cuda()\n",
    "print(pos_idx.shape, vtx_pos.shape)\n",
    "\n",
    "# model_dir = os.path.join(b.utils.get_assets_dir(),\"bop/ycbv/models\")\n",
    "# idx = 14\n",
    "# mesh_path = os.path.join(model_dir,\"obj_\" + \"{}\".format(idx).rjust(6, '0') + \".ply\")\n",
    "# m = b.utils.load_mesh(mesh_path)\n",
    "# m = b.utils.scale_mesh(m, 1.0/100.0)\n",
    "\n",
    "# vtx_pos = torch.from_numpy(m.vertices.astype(np.float32)).cuda()\n",
    "# pos_idx = torch.from_numpy(m.faces.astype(np.int32)).cuda()\n",
    "# col_idx = torch.from_numpy(np.zeros((vtx_pos.shape[0],3)).astype(np.int32)).cuda()\n",
    "# vtx_col = torch.from_numpy(np.ones((1,3)).astype(np.float32)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb5415b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6f93c7-f7e8-427f-8ea5-365370a9560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_target = torch.tensor([0.0, 0.0, -5.0, 1.0, 1.2, 0.4, 1.0]).cuda()\n",
    "rast_target = render(glctx, torch.matmul(mvp, quaternion_to_matrix(pose_target)), vtx_pos, pos_idx,  resolution)\n",
    "img_target  = rast_target[0].detach().cpu().numpy()\n",
    "b.hstack_images([\n",
    "    b.get_depth_image(img_target[:,:,0]* 255.0) ,\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5a306-73ca-4981-aca2-1c041ae57f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_opt = torch.tensor([0.0, 0.0, -6.0, 1.0, 1.2, 0.4, 1.0],dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "loss_best   = np.inf\n",
    "\n",
    "rast_opt = render(glctx, torch.matmul(mvp, quaternion_to_matrix(pose_opt)), vtx_pos, pos_idx,  resolution)\n",
    "img_opt  = rast_opt[0].detach().cpu().numpy()\n",
    "b.hstack_images([\n",
    "    b.get_depth_image(img_opt[:,:,0]* 255.0) ,\n",
    "    b.get_depth_image(img_target[:,:,0]* 255.0) ,\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc06f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (rast_opt - rast_target)**2 # L2 norm.\n",
    "diff.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb98ecb0-6e55-4280-af4f-6639e5d69f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([pose_opt],  lr=0.00001)\n",
    "images = []\n",
    "\n",
    "for _ in tqdm(range(200)):    \n",
    "    rast_opt = render(glctx, torch.matmul(mvp, quaternion_to_matrix(pose_opt)), vtx_pos, pos_idx,  resolution)\n",
    "\n",
    "    diff = (rast_opt - rast_target)**2 # L2 norm.\n",
    "    loss = torch.mean(diff)\n",
    "    loss_val = float(loss)\n",
    "    \n",
    "    if (loss_val < loss_best) and (loss_val > 0.0):\n",
    "        loss_best = loss_val\n",
    "                \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss)    \n",
    "    with torch.no_grad():\n",
    "        pose_opt /= torch.sum(pose_opt**2)**0.5\n",
    "    \n",
    "    img_opt  = rast_opt[0].detach().cpu().numpy()\n",
    "    images.append(\n",
    "        b.hstack_images([\n",
    "            b.get_depth_image(img_opt[:,:,0]* 255.0) ,\n",
    "            b.get_depth_image(img_target[:,:,0]* 255.0) ,\n",
    "        ])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2651d8eb-75c3-4453-b58c-09e46ce2b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.vstack_images([images[0],images[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e1f6dc-31e1-4c33-97c3-d13fa8e5f34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b921bcb5-4d8b-4b0f-8b9f-f3d70ca43522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f58562-0672-4e28-810b-2e30e7c849e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15dc7cd-0aef-44c7-a821-368b512c9fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
