{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import diff_gaussian_rasterization as dgr\n",
    "from diff_gaussian_rasterization import GaussianRasterizationSettings, GaussianRasterizer\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import bayes3d as b\n",
    "import jax.numpy as jnp\n",
    "from random import randint\n",
    "import pytorch3d.transforms\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.setup_visualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsics = b.Intrinsics(\n",
    "    height=100,\n",
    "    width=100,\n",
    "    fx=100.0, fy=100.0,\n",
    "    cx=50.0, cy=50.0,\n",
    "    near=0.01, far=2.5\n",
    ")\n",
    "fovX = jnp.arctan(intrinsics.width / 2 / intrinsics.fx) * 2\n",
    "fovY = jnp.arctan(intrinsics.height / 2 / intrinsics.fy) * 2\n",
    "tan_fovx = math.tan(fovX)\n",
    "tan_fovy = math.tan(fovY)\n",
    "\n",
    "\n",
    "def getProjectionMatrix(intrinsics):\n",
    "    top = intrinsics.near / intrinsics.fy * intrinsics.height / 2.0\n",
    "    bottom = -top\n",
    "    right = intrinsics.near / intrinsics.fy * intrinsics.height / 2.0\n",
    "    left = -right\n",
    "\n",
    "    P = torch.zeros(4, 4)\n",
    "\n",
    "    z_sign = 1.0\n",
    "\n",
    "    P[0, 0] = 2.0 * intrinsics.near / (right - left)\n",
    "    P[1, 1] = 2.0 * intrinsics.near / (top - bottom)\n",
    "    P[0, 2] = (right + left) / (right - left)\n",
    "    P[1, 2] = (top + bottom) / (top - bottom)\n",
    "    P[2, 2] = z_sign * (intrinsics.far + intrinsics.near) / (intrinsics.far - intrinsics.near)\n",
    "    P[2, 3] = -2.0 * (intrinsics.far * intrinsics.near) / (intrinsics.far - intrinsics.near)\n",
    "    P[3, 2] = z_sign\n",
    "    return torch.transpose(P, 0, 1)\n",
    "\n",
    "proj_matrix = torch.tensor(getProjectionMatrix(intrinsics), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.setup_renderer(intrinsics)\n",
    "model_dir = os.path.join(b.utils.get_assets_dir(),\"bop/ycbv/models\")\n",
    "mesh_path = os.path.join(model_dir,\"obj_\" + \"{}\".format(17).rjust(6, '0') + \".ply\")\n",
    "b.RENDERER.add_mesh_from_file(mesh_path, scaling_factor=1.0/1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_pose = b.transform_from_pos(jnp.array([0.0, 0.0, 0.3]))\n",
    "camera_poses = [jnp.eye(4), b.transform_from_axis_angle(jnp.array([1.0, 0.0, 0.0]), jnp.pi/40), b.transform_from_axis_angle(jnp.array([1.0, 0.0, 0.0]), jnp.pi/20)]\n",
    "\n",
    "point_cloud_images = [b.RENDERER.render(b.inverse_pose(cp) @ object_pose[None,...], jnp.array([0])) for cp in camera_poses]\n",
    "b.hstack_images([b.get_depth_image(img[:,:,2]) for img in point_cloud_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_pose = jnp.eye(4)\n",
    "view_matrix = torch.transpose(torch.tensor(np.array(b.inverse_pose(camera_pose))),0,1).cuda()\n",
    "raster_settings = GaussianRasterizationSettings(\n",
    "    image_height=int(intrinsics.height),\n",
    "    image_width=int(intrinsics.width),\n",
    "    tanfovx=tan_fovx,\n",
    "    tanfovy=tan_fovy,\n",
    "    bg=torch.tensor([intrinsics.far, intrinsics.far, intrinsics.far]).cuda(),\n",
    "    scale_modifier=1.0,\n",
    "    viewmatrix=view_matrix,\n",
    "    projmatrix=view_matrix @ proj_matrix,\n",
    "    sh_degree=1,\n",
    "    campos=torch.zeros(3).cuda(),\n",
    "    prefiltered=False,\n",
    "    debug=None\n",
    ")\n",
    "rasterizer = GaussianRasterizer(raster_settings=raster_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means3D = torch.from_numpy(np.array(point_cloud_not_far)).float().to(device)\n",
    "means2D = torch.ones((N, 3),device= device)\n",
    "opacity = torch.ones((N, 1)).cuda() \n",
    "scales = torch.rand((N, 3)).cuda() * 0.001\n",
    "rotations = torch.rand((N, 4)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\n",
    "    {'params': [means3D], 'lr': 0.0001 \"name\": \"xyz\"},\n",
    "    # {'params': [opacity], 'lr': training_args.opacity_lr, \"name\": \"opacity\"},\n",
    "    {'params': [scales], 'lr': training_args.scaling_lr, \"name\": \"scaling\"},\n",
    "    {'params': [rotations], 'lr': training_args.rotation_lr, \"name\": \"rotation\"}\n",
    "]\n",
    "optimizer = torch.optim.Adam(l, lr=0.0, eps=1e-15)\n",
    "\n",
    "pbar = tqdm(range(1000))\n",
    "for _ in pbar:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = torch.tensor([0.0, 0.0, 0.5],device=device)\n",
    "quat =  torch.tensor(torch.rand(4,device=device) - 0.5,device=device)\n",
    "\n",
    "gt_rendered_image =  render(pos, quat).detach()\n",
    "depth_image = np.moveaxis(gt_rendered_image.detach().cpu().numpy(),0,-1)[...,2]\n",
    "b.show_cloud(\"1\", b.unproject_depth_jit(depth_image, intrinsics).reshape(-1,3))\n",
    "viz_gt = b.get_depth_image(depth_image)\n",
    "viz_gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = torch.tensor([0.0, 0.0, 0.5],device=device, requires_grad=True)\n",
    "quat =  torch.tensor(torch.rand(4,device=device) - 0.5,device=device, requires_grad=True)\n",
    "rendered_image =  render(pos, quat)\n",
    "depth_image = np.moveaxis(rendered_image.detach().cpu().numpy(),0,-1)[...,2]\n",
    "b.show_cloud(\"1\", b.unproject_depth_jit(depth_image, intrinsics).reshape(-1,3))\n",
    "viz = b.get_depth_image(depth_image)\n",
    "b.hstack_images([viz, viz_gt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': [pos], 'lr': 0.001, \"name\": \"pos\"},\n",
    "    {'params': [quat], 'lr': 0.001, \"name\": \"quat\"},\n",
    "], lr=0.0, eps=1e-15)\n",
    "\n",
    "pbar = tqdm(range(1000))\n",
    "for _ in pbar:\n",
    "    rendered_image =  render(pos, quat)\n",
    "    loss = torch.abs(gt_rendered_image - rendered_image).mean()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pbar.set_description(f\"{loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "depth_image = np.moveaxis(rendered_image.detach().cpu().numpy(),0,-1)[...,2]\n",
    "b.show_cloud(\"1\", b.unproject_depth_jit(depth_image, intrinsics).reshape(-1,3))\n",
    "viz = b.get_depth_image(depth_image)\n",
    "b.hstack_images([viz, viz_gt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
