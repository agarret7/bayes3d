{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import diff_gaussian_rasterization as dgr\n",
    "from diff_gaussian_rasterization import GaussianRasterizationSettings, GaussianRasterizer\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import bayes3d as b\n",
    "import jax.numpy as jnp\n",
    "from random import randint\n",
    "import pytorch3d.transforms\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.setup_visualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(b.utils.get_assets_dir(),\"bop/ycbv/models\")\n",
    "mesh_path = os.path.join(model_dir,\"obj_\" + \"{}\".format(19).rjust(6, '0') + \".ply\")\n",
    "mesh = b.utils.load_mesh(mesh_path)\n",
    "vertices = torch.tensor(np.array(jnp.array(mesh.vertices) / 1000.0),device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsics = b.Intrinsics(\n",
    "    height=100,\n",
    "    width=100,\n",
    "    fx=100.0, fy=100.0,\n",
    "    cx=50.0, cy=50.0,\n",
    "    near=0.01, far=2.5\n",
    ")\n",
    "fovX = jnp.arctan(intrinsics.width / 2 / intrinsics.fx) * 2\n",
    "fovY = jnp.arctan(intrinsics.height / 2 / intrinsics.fy) * 2\n",
    "tan_fovx = math.tan(fovX)\n",
    "tan_fovy = math.tan(fovY)\n",
    "\n",
    "\n",
    "def getProjectionMatrix(intrinsics):\n",
    "    top = intrinsics.near / intrinsics.fy * intrinsics.height / 2.0\n",
    "    bottom = -top\n",
    "    right = intrinsics.near / intrinsics.fy * intrinsics.height / 2.0\n",
    "    left = -right\n",
    "\n",
    "    P = torch.zeros(4, 4)\n",
    "\n",
    "    z_sign = 1.0\n",
    "\n",
    "    P[0, 0] = 2.0 * intrinsics.near / (right - left)\n",
    "    P[1, 1] = 2.0 * intrinsics.near / (top - bottom)\n",
    "    P[0, 2] = (right + left) / (right - left)\n",
    "    P[1, 2] = (top + bottom) / (top - bottom)\n",
    "    P[2, 2] = z_sign * (intrinsics.far + intrinsics.near) / (intrinsics.far - intrinsics.near)\n",
    "    P[2, 3] = -2.0 * (intrinsics.far * intrinsics.near) / (intrinsics.far - intrinsics.near)\n",
    "    P[3, 2] = z_sign\n",
    "    return torch.transpose(P, 0, 1)\n",
    "\n",
    "proj_matrix = torch.tensor(getProjectionMatrix(intrinsics), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posevec_to_matrix(position, quat):\n",
    "    return torch.cat(\n",
    "        (\n",
    "            torch.cat((pytorch3d.transforms.quaternion_to_matrix(quat), position.unsqueeze(1)), 1),\n",
    "            torch.tensor([[0.0, 0.0, 0.0, 1.0]],device=device),\n",
    "        ),\n",
    "        0,\n",
    "    )\n",
    "def apply_transform(points, transform):\n",
    "    rels_ = torch.cat(\n",
    "        (\n",
    "            points,\n",
    "            torch.ones((points.shape[0], 1),  device=device),\n",
    "        ),\n",
    "        1,\n",
    "    )\n",
    "    return torch.einsum(\"ij, aj -> ai\", transform, rels_)[...,:3]\n",
    "position = torch.tensor([0.0, 0.1, 0.2], device=device)\n",
    "quat = torch.tensor([1.0, 0.1, 0.2, 0.3],device=device)\n",
    "points = torch.zeros((5,3), device = device)\n",
    "print(apply_transform(points, posevec_to_matrix(position, quat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_pose = jnp.eye(4)\n",
    "view_matrix = torch.transpose(torch.tensor(np.array(b.inverse_pose(camera_pose))),0,1).cuda()\n",
    "raster_settings = GaussianRasterizationSettings(\n",
    "    image_height=int(intrinsics.height),\n",
    "    image_width=int(intrinsics.width),\n",
    "    tanfovx=tan_fovx,\n",
    "    tanfovy=tan_fovy,\n",
    "    bg=torch.tensor([intrinsics.far, intrinsics.far, intrinsics.far]).cuda(),\n",
    "    scale_modifier=1.0,\n",
    "    viewmatrix=view_matrix,\n",
    "    projmatrix=view_matrix @ proj_matrix,\n",
    "    sh_degree=1,\n",
    "    campos=torch.zeros(3).cuda(),\n",
    "    prefiltered=False,\n",
    "    debug=None\n",
    ")\n",
    "rasterizer = GaussianRasterizer(raster_settings=raster_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(pos,quat):\n",
    "    means3D = apply_transform(vertices, posevec_to_matrix(pos, quat))\n",
    "    N = means3D.shape[0]\n",
    "    means2D = torch.ones((N, 3),requires_grad=True, device=device)\n",
    "    opacity = torch.rand((N, 1),requires_grad=True,device=device)\n",
    "    scales = torch.tensor( 0.01 * torch.rand((N, 3)),requires_grad=True,device=device)\n",
    "    rotations = torch.rand((N, 4),requires_grad=True,device=device)\n",
    "\n",
    "    gt_rendered_image, radii = rasterizer(\n",
    "        means3D = means3D,\n",
    "        means2D = means2D,\n",
    "        shs = None,\n",
    "        colors_precomp = means3D[:,2:3].repeat(1,3),\n",
    "        opacities = opacity,\n",
    "        scales = scales,\n",
    "        rotations = rotations\n",
    "    )\n",
    "    return gt_rendered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = torch.tensor([0.0, 0.0, 0.5],device=device)\n",
    "quat =  torch.tensor(torch.rand(4,device=device) - 0.5,device=device)\n",
    "\n",
    "gt_rendered_image =  render(pos, quat).detach()\n",
    "depth_image = np.moveaxis(gt_rendered_image.detach().cpu().numpy(),0,-1)[...,2]\n",
    "b.show_cloud(\"1\", b.unproject_depth_jit(depth_image, intrinsics).reshape(-1,3))\n",
    "viz_gt = b.get_depth_image(depth_image)\n",
    "viz_gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = torch.tensor([0.0, 0.0, 0.5],device=device, requires_grad=True)\n",
    "quat =  torch.tensor(torch.rand(4,device=device) - 0.5,device=device, requires_grad=True)\n",
    "rendered_image =  render(pos, quat)\n",
    "depth_image = np.moveaxis(rendered_image.detach().cpu().numpy(),0,-1)[...,2]\n",
    "b.show_cloud(\"1\", b.unproject_depth_jit(depth_image, intrinsics).reshape(-1,3))\n",
    "viz = b.get_depth_image(depth_image)\n",
    "b.hstack_images([viz, viz_gt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': [pos], 'lr': 0.001, \"name\": \"pos\"},\n",
    "    {'params': [quat], 'lr': 0.001, \"name\": \"quat\"},\n",
    "], lr=0.0, eps=1e-15)\n",
    "\n",
    "pbar = tqdm(range(1000))\n",
    "for _ in pbar:\n",
    "    rendered_image =  render(pos, quat)\n",
    "    loss = torch.abs(gt_rendered_image - rendered_image).mean()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pbar.set_description(f\"{loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "depth_image = np.moveaxis(rendered_image.detach().cpu().numpy(),0,-1)[...,2]\n",
    "b.show_cloud(\"1\", b.unproject_depth_jit(depth_image, intrinsics).reshape(-1,3))\n",
    "viz = b.get_depth_image(depth_image)\n",
    "b.hstack_images([viz, viz_gt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
