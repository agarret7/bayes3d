{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayes3d as b\n",
    "import jax.numpy as jnp\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7020/static/\n"
     ]
    }
   ],
   "source": [
    "b.setup_visualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E rasterize_gl.cpp:121] OpenGL version reported as 4.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing frame buffer size to (width, height, depth) = (128, 128, 1024)\n",
      "Centering mesh with translation [-0.09099948 -1.499594   -0.01582694]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "intrinsics = b.Intrinsics(\n",
    "    height=100,\n",
    "    width=100,\n",
    "    fx=50.0, fy=50.0,\n",
    "    cx=50.0, cy=50.0,\n",
    "    near=0.001, far=16.0\n",
    ")\n",
    "\n",
    "import trimesh\n",
    "def as_mesh(scene_or_mesh):\n",
    "    \"\"\"\n",
    "    Convert a possible scene to a mesh.\n",
    "\n",
    "    If conversion occurs, the returned mesh has only vertex and face data.\n",
    "    \"\"\"\n",
    "    if isinstance(scene_or_mesh, trimesh.Scene):\n",
    "        if len(scene_or_mesh.geometry) == 0:\n",
    "            mesh = None  # empty scene\n",
    "        else:\n",
    "            # we lose texture information here\n",
    "            mesh = trimesh.util.concatenate(\n",
    "                tuple(trimesh.Trimesh(vertices=g.vertices, faces=g.faces)\n",
    "                    for g in scene_or_mesh.geometry.values()))\n",
    "    else:\n",
    "        assert(isinstance(mesh, trimesh.Trimesh))\n",
    "        mesh = scene_or_mesh\n",
    "    return mesh\n",
    "mesh  =as_mesh(trimesh.load('InteriorTest.obj'))\n",
    "mesh.vertices  = mesh.vertices * jnp.array([1.0, -1.0, 1.0])\n",
    "b.setup_renderer(intrinsics)\n",
    "b.RENDERER.add_mesh(mesh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = [jnp.eye(4)]\n",
    "transform = b.transform_from_rot_and_pos(b.rotation_from_axis_angle(jnp.array([0.0, 1.0, 0.0]), -jnp.pi/100.0), jnp.array([0.1, 0.0, 0.0]))\n",
    "for _ in range(30): sequence.append(sequence[-1] @ transform)\n",
    "camera_poses = jnp.stack(sequence)\n",
    "inverse_camera_poses = b.inverse_pose(camera_poses)\n",
    "images = b.RENDERER.render_many(inverse_camera_poses[:,None,...],jnp.array([0]))[...,:3]\n",
    "viz_images = [b.get_depth_image(images[i,...,2], max=10.0) for i in range(images.shape[0])]\n",
    "b.make_gif_from_pil_images(viz_images, 'room.gif')\n",
    "b.clear()\n",
    "for i in range(len(sequence)):\n",
    "    b.show_pose(f\"{i}\", sequence[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_deltas = b.utils.make_translation_grid_enumeration(-0.2, -0.2, -0.2, 0.2, 0.2, 0.2, 25, 25, 25)\n",
    "rotation_deltas = jax.vmap(lambda key: b.distributions.gaussian_vmf_zero_mean(key, 0.0001, 800.0))(\n",
    "    jax.random.split(jax.random.PRNGKey(30), 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_and_select(current_pose, diffs, obs_img, variance):\n",
    "    possible_poses = jnp.einsum(\"aij,jk->aik\", diffs, current_pose)\n",
    "    rendered_imgs = b.RENDERER.render_many(b.inverse_pose(possible_poses)[:,None,...], jnp.array([0]))[...,:3]\n",
    "    scores = jax.vmap(b.threedp3_likelihood, in_axes=(None, 0, None, None))(obs_img, rendered_imgs, variance, 0.0)\n",
    "    return possible_poses[jnp.argmax(scores)], scores.max()\n",
    "grid_and_select_jit = jax.jit(grid_and_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1\n",
    "current_pose = camera_poses[0]\n",
    "b.clear()\n",
    "b.show_pose(f\"current_pose\", current_pose)\n",
    "b.show_pose(f\"ground_truth\", camera_poses[T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_deltas = b.utils.make_translation_grid_enumeration(-0.1, -0.1, -0.1, 0.1, 0.1, 0.1, 25, 25, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_deltas = b.utils.make_translation_grid_enumeration(-0.05, -0.05, -0.05, 0.05, 0.05, 0.05, 25, 25, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.425\n"
     ]
    }
   ],
   "source": [
    "T = 1\n",
    "b.clear()\n",
    "current_pose,score = grid_and_select_jit(current_pose, translation_deltas, images[T], 0.02)\n",
    "# current_pose,score = grid_and_select_jit(current_pose, rotation_deltas, images[T], 0.02)\n",
    "print(score)\n",
    "b.show_pose(f\"current_pose\", current_pose)\n",
    "b.show_pose(f\"ground_truth\", camera_poses[T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0000000e+00  0.0000000e+00  0.0000000e+00  6.6666678e-02]\n",
      " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  1.8626451e-08]\n",
      " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00 -4.1666478e-03]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00]]\n",
      "[[ 0.99950653  0.         -0.03141076  0.1       ]\n",
      " [ 0.          1.          0.          0.        ]\n",
      " [ 0.03141076  0.          0.99950653  0.        ]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(current_pose)\n",
    "print(camera_poses[T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(50., dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.threedp3_likelihood(images[T],images[T], 0.02, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.make_gif_from_pil_images(viz_images, 'room.gif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.show_trimesh(\"1\",b.RENDERER.meshes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 100, 100, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
