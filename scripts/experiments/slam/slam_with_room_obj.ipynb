{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayes3d as b\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7041/static/\n"
     ]
    }
   ],
   "source": [
    "b.setup_visualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "intrinsics = b.Intrinsics(\n",
    "    height=100,\n",
    "    width=100,\n",
    "    fx=50.0, fy=50.0,\n",
    "    cx=50.0, cy=50.0,\n",
    "    near=0.001, far=16.0\n",
    ")\n",
    "from bayes3d.rendering.nvdiffrast_jax.jax_renderer import Renderer as JaxRenderer\n",
    "jax_renderer = JaxRenderer(intrinsics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import trimesh\n",
    "def as_mesh(scene_or_mesh):\n",
    "    \"\"\"\n",
    "    Convert a possible scene to a mesh.\n",
    "\n",
    "    If conversion occurs, the returned mesh has only vertex and face data.\n",
    "    \"\"\"\n",
    "    if isinstance(scene_or_mesh, trimesh.Scene):\n",
    "        if len(scene_or_mesh.geometry) == 0:\n",
    "            mesh = None  # empty scene\n",
    "        else:\n",
    "            # we lose texture information here\n",
    "            mesh = trimesh.util.concatenate(\n",
    "                tuple(trimesh.Trimesh(vertices=g.vertices, faces=g.faces)\n",
    "                    for g in scene_or_mesh.geometry.values()))\n",
    "    else:\n",
    "        assert(isinstance(mesh, trimesh.Trimesh))\n",
    "        mesh = scene_or_mesh\n",
    "    return mesh\n",
    "mesh  =as_mesh(trimesh.load('InteriorTest.obj'))\n",
    "mesh.vertices  = mesh.vertices * jnp.array([1.0, -1.0, 1.0]) + jnp.array([0.0, 1.0, 0.0])\n",
    "vertices = mesh.vertices\n",
    "faces = mesh.faces\n",
    "\n",
    "b.show_trimesh(\"1\",mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = [jnp.eye(4)]\n",
    "transform = b.transform_from_rot_and_pos(b.rotation_from_axis_angle(jnp.array([0.0, 1.0, 0.0]), -jnp.pi/100000.0), jnp.array([0.0, 0.0, 0.1]))\n",
    "for _ in range(25): sequence.append(sequence[-1] @ transform)\n",
    "camera_poses = jnp.stack(sequence)\n",
    "b.clear()\n",
    "for i in range(len(sequence)):\n",
    "    b.show_pose(f\"{i}\", sequence[i])\n",
    "b.show_trimesh(\"1\",mesh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_images = [\n",
    "    jax_renderer.render(vertices, faces, b.inverse_pose(p), intrinsics)[0][0,...]\n",
    "    for p in camera_poses\n",
    "]\n",
    "b.make_gif_from_pil_images([b.get_depth_image(img, remove_max=False) for img in gt_images], \"gt.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(trans, q, gt_img):\n",
    "    camera_pose = b.translation_and_quaternion_to_pose_matrix(trans, q)\n",
    "    img = jax_renderer.render(vertices, faces, b.inverse_pose(camera_pose), intrinsics)[0][0,...]\n",
    "    return (jnp.abs(img - gt_img)).mean()\n",
    "\n",
    "value_and_grad_jit = jax.jit(jax.value_and_grad(loss, argnums=(0,1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.clear()\n",
    "b.show_pose(\"actual\", camera_poses[1])\n",
    "tr,q = b.pose_matrix_to_translation_and_quaternion(camera_poses[0])\n",
    "b.show_pose(\"inferred\", b.translation_and_quaternion_to_pose_matrix(tr,q), size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start  (Array(0.39068013, dtype=float32), (Array([ 0.10627548,  0.13037287, -0.3495799 ], dtype=float32), Array([ 0.        ,  0.10087404,  0.48157406, -0.34359443], dtype=float32)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.11451186239719391: 100%|██████████| 200/200 [00:00<00:00, 384.84it/s] \n"
     ]
    }
   ],
   "source": [
    "print(\"start \" , value_and_grad_jit(tr, q, gt_images[1]))\n",
    "poses = []\n",
    "pbar = tqdm(range(200))\n",
    "timestep = 1\n",
    "for _  in pbar:\n",
    "    loss, (g1, g2) = value_and_grad_jit(tr, q, gt_images[timestep])\n",
    "    tr -= g1 * 0.01\n",
    "    q -= g2 * 0.01\n",
    "    pbar.set_description(f\"{loss}\")\n",
    "    # poses.append(b.translation_and_quaternion_to_pose_matrix(tr,q))\n",
    "b.show_pose(\"inferred\", b.translation_and_quaternion_to_pose_matrix(tr,q), size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.clear()\n",
    "b.show_pose(\"actual\", camera_poses[1])\n",
    "tr,q = b.pose_matrix_to_translation_and_quaternion(camera_poses[0])\n",
    "b.show_pose(\"inferred\", b.translation_and_quaternion_to_pose_matrix(tr,q), size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start  (Array(0.39068013, dtype=float32), (Array([ 0.10627548,  0.13037287, -0.3495799 ], dtype=float32), Array([ 0.        ,  0.10087411,  0.48157406, -0.3435945 ], dtype=float32)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.3816789984703064: 100%|██████████| 200/200 [00:00<00:00, 276.31it/s]\n",
      "0.3915194272994995: 100%|██████████| 200/200 [00:00<00:00, 287.50it/s]\n",
      "0.22637736797332764: 100%|██████████| 200/200 [00:00<00:00, 271.57it/s]\n",
      "0.2539404630661011: 100%|██████████| 200/200 [00:00<00:00, 280.13it/s]\n",
      "0.03320816904306412: 100%|██████████| 200/200 [00:00<00:00, 280.94it/s]\n",
      "0.03555193543434143: 100%|██████████| 200/200 [00:00<00:00, 280.71it/s]\n",
      "0.15251809358596802: 100%|██████████| 200/200 [00:00<00:00, 266.10it/s]\n",
      "0.17262689769268036: 100%|██████████| 200/200 [00:00<00:00, 277.07it/s]\n",
      "0.19562497735023499: 100%|██████████| 200/200 [00:00<00:00, 283.27it/s]\n",
      "0.07484032958745956: 100%|██████████| 200/200 [00:00<00:00, 259.38it/s]\n",
      "0.025297656655311584: 100%|██████████| 200/200 [00:00<00:00, 262.83it/s]\n",
      "0.051032885909080505: 100%|██████████| 200/200 [00:00<00:00, 250.05it/s]\n",
      "0.012134687043726444: 100%|██████████| 200/200 [00:00<00:00, 282.20it/s]\n",
      "0.032516807317733765: 100%|██████████| 200/200 [00:00<00:00, 281.59it/s]\n",
      "0.030950140208005905: 100%|██████████| 200/200 [00:00<00:00, 286.76it/s]\n",
      "0.024326851591467857: 100%|██████████| 200/200 [00:00<00:00, 276.59it/s]\n",
      "0.0241733118891716: 100%|██████████| 200/200 [00:00<00:00, 279.04it/s]\n",
      "0.005503849592059851: 100%|██████████| 200/200 [00:00<00:00, 281.89it/s]\n",
      "0.013583630323410034: 100%|██████████| 200/200 [00:00<00:00, 281.28it/s]\n",
      "0.003240253310650587: 100%|██████████| 200/200 [00:00<00:00, 270.68it/s]\n",
      "0.020574131980538368: 100%|██████████| 200/200 [00:00<00:00, 265.75it/s]\n",
      "0.00414165947586298: 100%|██████████| 200/200 [00:00<00:00, 273.28it/s]\n",
      "0.012831118889153004: 100%|██████████| 200/200 [00:00<00:00, 271.77it/s]\n",
      "0.0025637538637965918: 100%|██████████| 200/200 [00:00<00:00, 281.48it/s]\n",
      "0.012781214900314808: 100%|██████████| 200/200 [00:00<00:00, 281.24it/s]\n",
      "0.004330799914896488: 100%|██████████| 200/200 [00:00<00:00, 283.05it/s]\n",
      "100%|██████████| 26/26 [00:20<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"start \" , value_and_grad_jit(tr, q, gt_images[1]))\n",
    "poses = []\n",
    "pbar2 = tqdm(range(len(gt_images)))\n",
    "for timestep  in pbar2:\n",
    "    pbar = tqdm(range(200))\n",
    "    b.show_pose(\"2\", b.translation_and_quaternion_to_pose_matrix(tr,q), size=0.1)\n",
    "    for _  in pbar:\n",
    "        loss, (g1, g2) = value_and_grad_jit(tr, q, gt_images[timestep])\n",
    "        tr -= g1 * 0.01\n",
    "        q -= g2 * 0.01\n",
    "        pbar.set_description(f\"{loss}\")\n",
    "    b.show_pose(\"actual\", camera_poses[timestep])\n",
    "    b.show_pose(\"inferred\", b.translation_and_quaternion_to_pose_matrix(tr,q), size=0.1)\n",
    "    poses.append(b.translation_and_quaternion_to_pose_matrix(tr,q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.clear()\n",
    "for i in range(len(poses)):\n",
    "    b.show_pose(f\"{i}\", poses[i])\n",
    "    b.show_pose(f\"{i}_actual\", camera_poses[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.show_pose(\"2\", b.translation_and_quaternion_to_pose_matrix(tr,q), size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# b.show_pose(\"2\", "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.43455184, dtype=float32),\n",
       " (Array([-0.15023103, -0.33511856,  0.05152562], dtype=float32),\n",
       "  Array([ 0.        ,  1.6910034 , -0.15435895,  0.6346966 ], dtype=float32)))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_and_grad_jit(*b.pose_matrix_to_translation_and_quaternion(camera_poses[0]), gt_images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_deltas = b.utils.make_translation_grid_enumeration(-0.2, -0.2, -0.2, 0.2, 0.2, 0.2, 25, 25, 25)\n",
    "rotation_deltas = jax.vmap(lambda key: b.distributions.gaussian_vmf_zero_mean(key, 0.0001, 800.0))(\n",
    "    jax.random.split(jax.random.PRNGKey(30), 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_and_select(current_pose, diffs, obs_img, variance):\n",
    "    possible_poses = jnp.einsum(\"aij,jk->aik\", diffs, current_pose)\n",
    "    rendered_imgs = b.RENDERER.render_many(b.inverse_pose(possible_poses)[:,None,...], jnp.array([0]))[...,:3]\n",
    "    scores = jax.vmap(b.threedp3_likelihood, in_axes=(None, 0, None, None))(obs_img, rendered_imgs, variance, 0.0)\n",
    "    return possible_poses[jnp.argmax(scores)], scores.max()\n",
    "grid_and_select_jit = jax.jit(grid_and_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1\n",
    "current_pose = camera_poses[0]\n",
    "b.clear()\n",
    "b.show_pose(f\"current_pose\", current_pose)\n",
    "b.show_pose(f\"ground_truth\", camera_poses[T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_deltas = b.utils.make_translation_grid_enumeration(-0.1, -0.1, -0.1, 0.1, 0.1, 0.1, 25, 25, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_deltas = b.utils.make_translation_grid_enumeration(-0.05, -0.05, -0.05, 0.05, 0.05, 0.05, 25, 25, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.425\n"
     ]
    }
   ],
   "source": [
    "T = 1\n",
    "b.clear()\n",
    "current_pose,score = grid_and_select_jit(current_pose, translation_deltas, images[T], 0.02)\n",
    "# current_pose,score = grid_and_select_jit(current_pose, rotation_deltas, images[T], 0.02)\n",
    "print(score)\n",
    "b.show_pose(f\"current_pose\", current_pose)\n",
    "b.show_pose(f\"ground_truth\", camera_poses[T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0000000e+00  0.0000000e+00  0.0000000e+00  6.6666678e-02]\n",
      " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  1.8626451e-08]\n",
      " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00 -4.1666478e-03]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00]]\n",
      "[[ 0.99950653  0.         -0.03141076  0.1       ]\n",
      " [ 0.          1.          0.          0.        ]\n",
      " [ 0.03141076  0.          0.99950653  0.        ]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(current_pose)\n",
    "print(camera_poses[T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(50., dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.threedp3_likelihood(images[T],images[T], 0.02, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.make_gif_from_pil_images(viz_images, 'room.gif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.show_trimesh(\"1\",b.RENDERER.meshes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 100, 100, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
